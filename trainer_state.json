{
  "best_global_step": 2600,
  "best_metric": 0.865452766418457,
  "best_model_checkpoint": "./smolLM-bodywash-finetuned/checkpoint-2600",
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 2616,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011474469305794608,
      "grad_norm": 0.29985958337783813,
      "learning_rate": 3.6e-05,
      "loss": 4.1795,
      "step": 10
    },
    {
      "epoch": 0.022948938611589215,
      "grad_norm": 0.40946608781814575,
      "learning_rate": 7.6e-05,
      "loss": 3.9595,
      "step": 20
    },
    {
      "epoch": 0.03442340791738382,
      "grad_norm": 0.5394147038459778,
      "learning_rate": 0.000116,
      "loss": 3.383,
      "step": 30
    },
    {
      "epoch": 0.04589787722317843,
      "grad_norm": 0.39663755893707275,
      "learning_rate": 0.00015600000000000002,
      "loss": 2.4545,
      "step": 40
    },
    {
      "epoch": 0.05737234652897304,
      "grad_norm": 0.5684530138969421,
      "learning_rate": 0.000196,
      "loss": 2.2012,
      "step": 50
    },
    {
      "epoch": 0.05737234652897304,
      "eval_loss": 1.9440882205963135,
      "eval_runtime": 97.8259,
      "eval_samples_per_second": 7.922,
      "eval_steps_per_second": 1.983,
      "step": 50
    },
    {
      "epoch": 0.06884681583476764,
      "grad_norm": 0.29403671622276306,
      "learning_rate": 0.00019929851909586906,
      "loss": 1.9409,
      "step": 60
    },
    {
      "epoch": 0.08032128514056225,
      "grad_norm": 0.34573742747306824,
      "learning_rate": 0.00019851909586905692,
      "loss": 1.698,
      "step": 70
    },
    {
      "epoch": 0.09179575444635686,
      "grad_norm": 0.37276020646095276,
      "learning_rate": 0.00019773967264224474,
      "loss": 1.7849,
      "step": 80
    },
    {
      "epoch": 0.10327022375215146,
      "grad_norm": 0.33288657665252686,
      "learning_rate": 0.00019696024941543257,
      "loss": 1.7251,
      "step": 90
    },
    {
      "epoch": 0.11474469305794607,
      "grad_norm": 0.36733871698379517,
      "learning_rate": 0.00019618082618862043,
      "loss": 1.7724,
      "step": 100
    },
    {
      "epoch": 0.11474469305794607,
      "eval_loss": 1.7061967849731445,
      "eval_runtime": 97.7794,
      "eval_samples_per_second": 7.926,
      "eval_steps_per_second": 1.984,
      "step": 100
    },
    {
      "epoch": 0.12621916236374067,
      "grad_norm": 0.3585256040096283,
      "learning_rate": 0.00019540140296180826,
      "loss": 1.634,
      "step": 110
    },
    {
      "epoch": 0.13769363166953527,
      "grad_norm": 0.3088202476501465,
      "learning_rate": 0.0001946219797349961,
      "loss": 1.7326,
      "step": 120
    },
    {
      "epoch": 0.1491681009753299,
      "grad_norm": 0.3492949903011322,
      "learning_rate": 0.00019384255650818394,
      "loss": 1.7572,
      "step": 130
    },
    {
      "epoch": 0.1606425702811245,
      "grad_norm": 0.3722287714481354,
      "learning_rate": 0.0001930631332813718,
      "loss": 1.6918,
      "step": 140
    },
    {
      "epoch": 0.1721170395869191,
      "grad_norm": 0.37512674927711487,
      "learning_rate": 0.00019228371005455963,
      "loss": 1.6117,
      "step": 150
    },
    {
      "epoch": 0.1721170395869191,
      "eval_loss": 1.6431503295898438,
      "eval_runtime": 97.7591,
      "eval_samples_per_second": 7.928,
      "eval_steps_per_second": 1.984,
      "step": 150
    },
    {
      "epoch": 0.18359150889271372,
      "grad_norm": 0.4844498932361603,
      "learning_rate": 0.00019150428682774748,
      "loss": 1.6999,
      "step": 160
    },
    {
      "epoch": 0.19506597819850832,
      "grad_norm": 0.36912083625793457,
      "learning_rate": 0.0001907248636009353,
      "loss": 1.6573,
      "step": 170
    },
    {
      "epoch": 0.20654044750430292,
      "grad_norm": 0.4557316303253174,
      "learning_rate": 0.00018994544037412317,
      "loss": 1.6159,
      "step": 180
    },
    {
      "epoch": 0.21801491681009752,
      "grad_norm": 0.441457062959671,
      "learning_rate": 0.000189166017147311,
      "loss": 1.6689,
      "step": 190
    },
    {
      "epoch": 0.22948938611589215,
      "grad_norm": 0.4145420491695404,
      "learning_rate": 0.00018838659392049885,
      "loss": 1.565,
      "step": 200
    },
    {
      "epoch": 0.22948938611589215,
      "eval_loss": 1.6022168397903442,
      "eval_runtime": 98.1442,
      "eval_samples_per_second": 7.897,
      "eval_steps_per_second": 1.977,
      "step": 200
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 0.42899829149246216,
      "learning_rate": 0.00018760717069368668,
      "loss": 1.589,
      "step": 210
    },
    {
      "epoch": 0.25243832472748134,
      "grad_norm": 0.4271092712879181,
      "learning_rate": 0.00018682774746687453,
      "loss": 1.724,
      "step": 220
    },
    {
      "epoch": 0.26391279403327594,
      "grad_norm": 0.4269919991493225,
      "learning_rate": 0.00018604832424006236,
      "loss": 1.6909,
      "step": 230
    },
    {
      "epoch": 0.27538726333907054,
      "grad_norm": 0.4445413649082184,
      "learning_rate": 0.00018526890101325022,
      "loss": 1.7639,
      "step": 240
    },
    {
      "epoch": 0.2868617326448652,
      "grad_norm": 0.42978641390800476,
      "learning_rate": 0.00018448947778643805,
      "loss": 1.4966,
      "step": 250
    },
    {
      "epoch": 0.2868617326448652,
      "eval_loss": 1.5707193613052368,
      "eval_runtime": 97.8135,
      "eval_samples_per_second": 7.923,
      "eval_steps_per_second": 1.983,
      "step": 250
    },
    {
      "epoch": 0.2983362019506598,
      "grad_norm": 0.4600571393966675,
      "learning_rate": 0.00018371005455962587,
      "loss": 1.6507,
      "step": 260
    },
    {
      "epoch": 0.3098106712564544,
      "grad_norm": 0.4431425929069519,
      "learning_rate": 0.00018293063133281373,
      "loss": 1.5972,
      "step": 270
    },
    {
      "epoch": 0.321285140562249,
      "grad_norm": 0.4688293933868408,
      "learning_rate": 0.00018215120810600156,
      "loss": 1.664,
      "step": 280
    },
    {
      "epoch": 0.3327596098680436,
      "grad_norm": 0.44794726371765137,
      "learning_rate": 0.0001813717848791894,
      "loss": 1.4833,
      "step": 290
    },
    {
      "epoch": 0.3442340791738382,
      "grad_norm": 0.5334165692329407,
      "learning_rate": 0.00018059236165237724,
      "loss": 1.5672,
      "step": 300
    },
    {
      "epoch": 0.3442340791738382,
      "eval_loss": 1.5473755598068237,
      "eval_runtime": 97.7287,
      "eval_samples_per_second": 7.93,
      "eval_steps_per_second": 1.985,
      "step": 300
    },
    {
      "epoch": 0.3557085484796328,
      "grad_norm": 0.4634541869163513,
      "learning_rate": 0.00017981293842556507,
      "loss": 1.5806,
      "step": 310
    },
    {
      "epoch": 0.36718301778542745,
      "grad_norm": 0.46639925241470337,
      "learning_rate": 0.00017903351519875293,
      "loss": 1.501,
      "step": 320
    },
    {
      "epoch": 0.37865748709122204,
      "grad_norm": 0.48335328698158264,
      "learning_rate": 0.00017825409197194076,
      "loss": 1.416,
      "step": 330
    },
    {
      "epoch": 0.39013195639701664,
      "grad_norm": 0.5299801826477051,
      "learning_rate": 0.0001774746687451286,
      "loss": 1.5038,
      "step": 340
    },
    {
      "epoch": 0.40160642570281124,
      "grad_norm": 0.4608047604560852,
      "learning_rate": 0.00017669524551831644,
      "loss": 1.6318,
      "step": 350
    },
    {
      "epoch": 0.40160642570281124,
      "eval_loss": 1.5217167139053345,
      "eval_runtime": 97.7894,
      "eval_samples_per_second": 7.925,
      "eval_steps_per_second": 1.984,
      "step": 350
    },
    {
      "epoch": 0.41308089500860584,
      "grad_norm": 0.5438259840011597,
      "learning_rate": 0.0001759158222915043,
      "loss": 1.6417,
      "step": 360
    },
    {
      "epoch": 0.42455536431440044,
      "grad_norm": 0.5711479783058167,
      "learning_rate": 0.00017513639906469215,
      "loss": 1.499,
      "step": 370
    },
    {
      "epoch": 0.43602983362019504,
      "grad_norm": 0.48091045022010803,
      "learning_rate": 0.00017435697583787998,
      "loss": 1.505,
      "step": 380
    },
    {
      "epoch": 0.4475043029259897,
      "grad_norm": 0.43626028299331665,
      "learning_rate": 0.00017357755261106784,
      "loss": 1.5681,
      "step": 390
    },
    {
      "epoch": 0.4589787722317843,
      "grad_norm": 0.5870484113693237,
      "learning_rate": 0.00017279812938425566,
      "loss": 1.5165,
      "step": 400
    },
    {
      "epoch": 0.4589787722317843,
      "eval_loss": 1.5010451078414917,
      "eval_runtime": 97.7154,
      "eval_samples_per_second": 7.931,
      "eval_steps_per_second": 1.985,
      "step": 400
    },
    {
      "epoch": 0.4704532415375789,
      "grad_norm": 0.4819395840167999,
      "learning_rate": 0.00017201870615744352,
      "loss": 1.4162,
      "step": 410
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 0.5387530326843262,
      "learning_rate": 0.00017123928293063135,
      "loss": 1.5227,
      "step": 420
    },
    {
      "epoch": 0.4934021801491681,
      "grad_norm": 0.5278536677360535,
      "learning_rate": 0.0001704598597038192,
      "loss": 1.6189,
      "step": 430
    },
    {
      "epoch": 0.5048766494549627,
      "grad_norm": 0.5460168123245239,
      "learning_rate": 0.00016968043647700703,
      "loss": 1.496,
      "step": 440
    },
    {
      "epoch": 0.5163511187607573,
      "grad_norm": 0.6379448175430298,
      "learning_rate": 0.00016890101325019486,
      "loss": 1.5846,
      "step": 450
    },
    {
      "epoch": 0.5163511187607573,
      "eval_loss": 1.482297420501709,
      "eval_runtime": 97.6731,
      "eval_samples_per_second": 7.935,
      "eval_steps_per_second": 1.986,
      "step": 450
    },
    {
      "epoch": 0.5278255880665519,
      "grad_norm": 0.5331240296363831,
      "learning_rate": 0.0001681215900233827,
      "loss": 1.4468,
      "step": 460
    },
    {
      "epoch": 0.5393000573723465,
      "grad_norm": 0.669530987739563,
      "learning_rate": 0.00016734216679657054,
      "loss": 1.5422,
      "step": 470
    },
    {
      "epoch": 0.5507745266781411,
      "grad_norm": 0.5536342263221741,
      "learning_rate": 0.00016656274356975837,
      "loss": 1.6047,
      "step": 480
    },
    {
      "epoch": 0.5622489959839357,
      "grad_norm": 0.5533602833747864,
      "learning_rate": 0.00016578332034294623,
      "loss": 1.5579,
      "step": 490
    },
    {
      "epoch": 0.5737234652897304,
      "grad_norm": 0.5591614246368408,
      "learning_rate": 0.00016500389711613406,
      "loss": 1.5036,
      "step": 500
    },
    {
      "epoch": 0.5737234652897304,
      "eval_loss": 1.4612212181091309,
      "eval_runtime": 97.5881,
      "eval_samples_per_second": 7.942,
      "eval_steps_per_second": 1.988,
      "step": 500
    },
    {
      "epoch": 0.5851979345955249,
      "grad_norm": 0.6587395668029785,
      "learning_rate": 0.0001642244738893219,
      "loss": 1.5422,
      "step": 510
    },
    {
      "epoch": 0.5966724039013196,
      "grad_norm": 0.5061312913894653,
      "learning_rate": 0.00016344505066250974,
      "loss": 1.421,
      "step": 520
    },
    {
      "epoch": 0.6081468732071141,
      "grad_norm": 0.6543156504631042,
      "learning_rate": 0.0001626656274356976,
      "loss": 1.4561,
      "step": 530
    },
    {
      "epoch": 0.6196213425129088,
      "grad_norm": 0.6821956038475037,
      "learning_rate": 0.00016188620420888543,
      "loss": 1.5068,
      "step": 540
    },
    {
      "epoch": 0.6310958118187033,
      "grad_norm": 0.59132981300354,
      "learning_rate": 0.00016110678098207328,
      "loss": 1.3448,
      "step": 550
    },
    {
      "epoch": 0.6310958118187033,
      "eval_loss": 1.4392257928848267,
      "eval_runtime": 97.7889,
      "eval_samples_per_second": 7.925,
      "eval_steps_per_second": 1.984,
      "step": 550
    },
    {
      "epoch": 0.642570281124498,
      "grad_norm": 0.7480852603912354,
      "learning_rate": 0.0001603273577552611,
      "loss": 1.467,
      "step": 560
    },
    {
      "epoch": 0.6540447504302926,
      "grad_norm": 0.6492536067962646,
      "learning_rate": 0.00015954793452844897,
      "loss": 1.4718,
      "step": 570
    },
    {
      "epoch": 0.6655192197360872,
      "grad_norm": 0.6537176966667175,
      "learning_rate": 0.0001587685113016368,
      "loss": 1.4426,
      "step": 580
    },
    {
      "epoch": 0.6769936890418818,
      "grad_norm": 0.6200145483016968,
      "learning_rate": 0.00015798908807482465,
      "loss": 1.3579,
      "step": 590
    },
    {
      "epoch": 0.6884681583476764,
      "grad_norm": 0.6148841977119446,
      "learning_rate": 0.00015720966484801248,
      "loss": 1.4047,
      "step": 600
    },
    {
      "epoch": 0.6884681583476764,
      "eval_loss": 1.417124629020691,
      "eval_runtime": 97.682,
      "eval_samples_per_second": 7.934,
      "eval_steps_per_second": 1.986,
      "step": 600
    },
    {
      "epoch": 0.699942627653471,
      "grad_norm": 0.6991332173347473,
      "learning_rate": 0.00015643024162120033,
      "loss": 1.3633,
      "step": 610
    },
    {
      "epoch": 0.7114170969592656,
      "grad_norm": 0.6026431918144226,
      "learning_rate": 0.00015565081839438816,
      "loss": 1.6799,
      "step": 620
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 0.5685957074165344,
      "learning_rate": 0.00015487139516757602,
      "loss": 1.4827,
      "step": 630
    },
    {
      "epoch": 0.7343660355708549,
      "grad_norm": 0.7282426953315735,
      "learning_rate": 0.00015409197194076385,
      "loss": 1.4259,
      "step": 640
    },
    {
      "epoch": 0.7458405048766494,
      "grad_norm": 0.6460018754005432,
      "learning_rate": 0.00015331254871395168,
      "loss": 1.4584,
      "step": 650
    },
    {
      "epoch": 0.7458405048766494,
      "eval_loss": 1.4035109281539917,
      "eval_runtime": 97.769,
      "eval_samples_per_second": 7.927,
      "eval_steps_per_second": 1.984,
      "step": 650
    },
    {
      "epoch": 0.7573149741824441,
      "grad_norm": 0.6107429265975952,
      "learning_rate": 0.0001525331254871395,
      "loss": 1.2657,
      "step": 660
    },
    {
      "epoch": 0.7687894434882386,
      "grad_norm": 0.7201909422874451,
      "learning_rate": 0.00015175370226032736,
      "loss": 1.4728,
      "step": 670
    },
    {
      "epoch": 0.7802639127940333,
      "grad_norm": 0.6702231764793396,
      "learning_rate": 0.0001509742790335152,
      "loss": 1.3605,
      "step": 680
    },
    {
      "epoch": 0.7917383820998278,
      "grad_norm": 0.8043104410171509,
      "learning_rate": 0.00015019485580670304,
      "loss": 1.37,
      "step": 690
    },
    {
      "epoch": 0.8032128514056225,
      "grad_norm": 0.7554386854171753,
      "learning_rate": 0.00014941543257989087,
      "loss": 1.3577,
      "step": 700
    },
    {
      "epoch": 0.8032128514056225,
      "eval_loss": 1.3849931955337524,
      "eval_runtime": 97.6281,
      "eval_samples_per_second": 7.938,
      "eval_steps_per_second": 1.987,
      "step": 700
    },
    {
      "epoch": 0.8146873207114171,
      "grad_norm": 0.666841983795166,
      "learning_rate": 0.00014863600935307873,
      "loss": 1.4137,
      "step": 710
    },
    {
      "epoch": 0.8261617900172117,
      "grad_norm": 0.718423068523407,
      "learning_rate": 0.00014785658612626656,
      "loss": 1.2476,
      "step": 720
    },
    {
      "epoch": 0.8376362593230063,
      "grad_norm": 0.8287259936332703,
      "learning_rate": 0.0001470771628994544,
      "loss": 1.3925,
      "step": 730
    },
    {
      "epoch": 0.8491107286288009,
      "grad_norm": 0.6617619395256042,
      "learning_rate": 0.00014629773967264224,
      "loss": 1.4439,
      "step": 740
    },
    {
      "epoch": 0.8605851979345955,
      "grad_norm": 0.7119974493980408,
      "learning_rate": 0.0001455183164458301,
      "loss": 1.4063,
      "step": 750
    },
    {
      "epoch": 0.8605851979345955,
      "eval_loss": 1.3690026998519897,
      "eval_runtime": 97.7573,
      "eval_samples_per_second": 7.928,
      "eval_steps_per_second": 1.985,
      "step": 750
    },
    {
      "epoch": 0.8720596672403901,
      "grad_norm": 0.7220584154129028,
      "learning_rate": 0.00014473889321901792,
      "loss": 1.3347,
      "step": 760
    },
    {
      "epoch": 0.8835341365461847,
      "grad_norm": 0.7139130234718323,
      "learning_rate": 0.00014395946999220578,
      "loss": 1.4705,
      "step": 770
    },
    {
      "epoch": 0.8950086058519794,
      "grad_norm": 0.9191529750823975,
      "learning_rate": 0.0001431800467653936,
      "loss": 1.3856,
      "step": 780
    },
    {
      "epoch": 0.9064830751577739,
      "grad_norm": 0.7815741896629333,
      "learning_rate": 0.00014240062353858146,
      "loss": 1.3582,
      "step": 790
    },
    {
      "epoch": 0.9179575444635686,
      "grad_norm": 0.6887747049331665,
      "learning_rate": 0.0001416212003117693,
      "loss": 1.4833,
      "step": 800
    },
    {
      "epoch": 0.9179575444635686,
      "eval_loss": 1.3471225500106812,
      "eval_runtime": 97.7043,
      "eval_samples_per_second": 7.932,
      "eval_steps_per_second": 1.986,
      "step": 800
    },
    {
      "epoch": 0.9294320137693631,
      "grad_norm": 0.7971627116203308,
      "learning_rate": 0.00014084177708495715,
      "loss": 1.3943,
      "step": 810
    },
    {
      "epoch": 0.9409064830751578,
      "grad_norm": 0.8366304636001587,
      "learning_rate": 0.00014006235385814498,
      "loss": 1.3225,
      "step": 820
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.7085193395614624,
      "learning_rate": 0.00013928293063133283,
      "loss": 1.3521,
      "step": 830
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 0.7403785586357117,
      "learning_rate": 0.00013850350740452066,
      "loss": 1.2698,
      "step": 840
    },
    {
      "epoch": 0.9753298909925416,
      "grad_norm": 0.8403043150901794,
      "learning_rate": 0.0001377240841777085,
      "loss": 1.3716,
      "step": 850
    },
    {
      "epoch": 0.9753298909925416,
      "eval_loss": 1.3319886922836304,
      "eval_runtime": 97.7207,
      "eval_samples_per_second": 7.931,
      "eval_steps_per_second": 1.985,
      "step": 850
    },
    {
      "epoch": 0.9868043602983362,
      "grad_norm": 0.9462764859199524,
      "learning_rate": 0.00013694466095089634,
      "loss": 1.3744,
      "step": 860
    },
    {
      "epoch": 0.9982788296041308,
      "grad_norm": 0.8697447180747986,
      "learning_rate": 0.00013616523772408417,
      "loss": 1.4219,
      "step": 870
    },
    {
      "epoch": 1.0091795754446358,
      "grad_norm": 0.8172240853309631,
      "learning_rate": 0.00013538581449727203,
      "loss": 1.1799,
      "step": 880
    },
    {
      "epoch": 1.0206540447504302,
      "grad_norm": 0.8214889168739319,
      "learning_rate": 0.00013460639127045986,
      "loss": 1.1654,
      "step": 890
    },
    {
      "epoch": 1.0321285140562249,
      "grad_norm": 0.8770334124565125,
      "learning_rate": 0.0001338269680436477,
      "loss": 1.1556,
      "step": 900
    },
    {
      "epoch": 1.0321285140562249,
      "eval_loss": 1.321656346321106,
      "eval_runtime": 97.7022,
      "eval_samples_per_second": 7.932,
      "eval_steps_per_second": 1.986,
      "step": 900
    },
    {
      "epoch": 1.0436029833620195,
      "grad_norm": 0.8848921656608582,
      "learning_rate": 0.00013304754481683554,
      "loss": 1.2787,
      "step": 910
    },
    {
      "epoch": 1.0550774526678142,
      "grad_norm": 0.8299767971038818,
      "learning_rate": 0.0001322681215900234,
      "loss": 1.2833,
      "step": 920
    },
    {
      "epoch": 1.0665519219736088,
      "grad_norm": 1.1186082363128662,
      "learning_rate": 0.00013148869836321123,
      "loss": 1.0901,
      "step": 930
    },
    {
      "epoch": 1.0780263912794033,
      "grad_norm": 1.0809862613677979,
      "learning_rate": 0.00013070927513639908,
      "loss": 1.1373,
      "step": 940
    },
    {
      "epoch": 1.089500860585198,
      "grad_norm": 0.9796647429466248,
      "learning_rate": 0.0001299298519095869,
      "loss": 1.1653,
      "step": 950
    },
    {
      "epoch": 1.089500860585198,
      "eval_loss": 1.3088860511779785,
      "eval_runtime": 97.7553,
      "eval_samples_per_second": 7.928,
      "eval_steps_per_second": 1.985,
      "step": 950
    },
    {
      "epoch": 1.1009753298909926,
      "grad_norm": 1.2866222858428955,
      "learning_rate": 0.00012915042868277477,
      "loss": 1.1638,
      "step": 960
    },
    {
      "epoch": 1.1124497991967872,
      "grad_norm": 1.1679884195327759,
      "learning_rate": 0.0001283710054559626,
      "loss": 1.1051,
      "step": 970
    },
    {
      "epoch": 1.1239242685025816,
      "grad_norm": 1.013214349746704,
      "learning_rate": 0.00012759158222915045,
      "loss": 1.2667,
      "step": 980
    },
    {
      "epoch": 1.1353987378083763,
      "grad_norm": 1.0606589317321777,
      "learning_rate": 0.00012681215900233828,
      "loss": 1.2684,
      "step": 990
    },
    {
      "epoch": 1.146873207114171,
      "grad_norm": 1.0168120861053467,
      "learning_rate": 0.00012603273577552613,
      "loss": 1.1479,
      "step": 1000
    },
    {
      "epoch": 1.146873207114171,
      "eval_loss": 1.2833256721496582,
      "eval_runtime": 97.7151,
      "eval_samples_per_second": 7.931,
      "eval_steps_per_second": 1.985,
      "step": 1000
    },
    {
      "epoch": 1.1583476764199656,
      "grad_norm": 1.0196177959442139,
      "learning_rate": 0.00012525331254871396,
      "loss": 1.1914,
      "step": 1010
    },
    {
      "epoch": 1.1698221457257603,
      "grad_norm": 1.1952941417694092,
      "learning_rate": 0.0001244738893219018,
      "loss": 1.1131,
      "step": 1020
    },
    {
      "epoch": 1.1812966150315547,
      "grad_norm": 1.1426364183425903,
      "learning_rate": 0.00012369446609508965,
      "loss": 1.1951,
      "step": 1030
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 1.1307637691497803,
      "learning_rate": 0.00012291504286827748,
      "loss": 1.2137,
      "step": 1040
    },
    {
      "epoch": 1.204245553643144,
      "grad_norm": 1.496749997138977,
      "learning_rate": 0.0001221356196414653,
      "loss": 1.1415,
      "step": 1050
    },
    {
      "epoch": 1.204245553643144,
      "eval_loss": 1.2612693309783936,
      "eval_runtime": 97.6311,
      "eval_samples_per_second": 7.938,
      "eval_steps_per_second": 1.987,
      "step": 1050
    },
    {
      "epoch": 1.2157200229489387,
      "grad_norm": 1.3388680219650269,
      "learning_rate": 0.00012135619641465317,
      "loss": 1.0915,
      "step": 1060
    },
    {
      "epoch": 1.2271944922547333,
      "grad_norm": 0.9816485047340393,
      "learning_rate": 0.000120576773187841,
      "loss": 1.1207,
      "step": 1070
    },
    {
      "epoch": 1.2386689615605277,
      "grad_norm": 1.031719446182251,
      "learning_rate": 0.00011979734996102884,
      "loss": 1.1938,
      "step": 1080
    },
    {
      "epoch": 1.2501434308663224,
      "grad_norm": 1.0868421792984009,
      "learning_rate": 0.00011901792673421667,
      "loss": 1.2294,
      "step": 1090
    },
    {
      "epoch": 1.261617900172117,
      "grad_norm": 1.0711463689804077,
      "learning_rate": 0.00011823850350740453,
      "loss": 1.1877,
      "step": 1100
    },
    {
      "epoch": 1.261617900172117,
      "eval_loss": 1.2379381656646729,
      "eval_runtime": 97.7285,
      "eval_samples_per_second": 7.93,
      "eval_steps_per_second": 1.985,
      "step": 1100
    },
    {
      "epoch": 1.2730923694779117,
      "grad_norm": 1.1428855657577515,
      "learning_rate": 0.00011745908028059236,
      "loss": 1.237,
      "step": 1110
    },
    {
      "epoch": 1.2845668387837064,
      "grad_norm": 1.070846438407898,
      "learning_rate": 0.00011667965705378021,
      "loss": 1.0667,
      "step": 1120
    },
    {
      "epoch": 1.2960413080895008,
      "grad_norm": 0.9646891951560974,
      "learning_rate": 0.00011590023382696804,
      "loss": 1.1908,
      "step": 1130
    },
    {
      "epoch": 1.3075157773952955,
      "grad_norm": 1.1176444292068481,
      "learning_rate": 0.0001151208106001559,
      "loss": 1.0403,
      "step": 1140
    },
    {
      "epoch": 1.31899024670109,
      "grad_norm": 1.1823487281799316,
      "learning_rate": 0.00011434138737334372,
      "loss": 1.0766,
      "step": 1150
    },
    {
      "epoch": 1.31899024670109,
      "eval_loss": 1.215259313583374,
      "eval_runtime": 97.8153,
      "eval_samples_per_second": 7.923,
      "eval_steps_per_second": 1.983,
      "step": 1150
    },
    {
      "epoch": 1.3304647160068848,
      "grad_norm": 1.3933634757995605,
      "learning_rate": 0.00011356196414653158,
      "loss": 1.05,
      "step": 1160
    },
    {
      "epoch": 1.3419391853126794,
      "grad_norm": 0.9364053010940552,
      "learning_rate": 0.00011278254091971941,
      "loss": 1.1536,
      "step": 1170
    },
    {
      "epoch": 1.3534136546184738,
      "grad_norm": 1.1301765441894531,
      "learning_rate": 0.00011200311769290725,
      "loss": 1.0371,
      "step": 1180
    },
    {
      "epoch": 1.3648881239242685,
      "grad_norm": 1.600080966949463,
      "learning_rate": 0.00011122369446609508,
      "loss": 1.028,
      "step": 1190
    },
    {
      "epoch": 1.3763625932300632,
      "grad_norm": 0.9735196232795715,
      "learning_rate": 0.00011044427123928293,
      "loss": 1.2531,
      "step": 1200
    },
    {
      "epoch": 1.3763625932300632,
      "eval_loss": 1.202874779701233,
      "eval_runtime": 97.6125,
      "eval_samples_per_second": 7.94,
      "eval_steps_per_second": 1.987,
      "step": 1200
    },
    {
      "epoch": 1.3878370625358576,
      "grad_norm": 1.3217071294784546,
      "learning_rate": 0.00010966484801247076,
      "loss": 1.0525,
      "step": 1210
    },
    {
      "epoch": 1.3993115318416522,
      "grad_norm": 1.0690374374389648,
      "learning_rate": 0.00010888542478565862,
      "loss": 1.1446,
      "step": 1220
    },
    {
      "epoch": 1.410786001147447,
      "grad_norm": 0.9759881496429443,
      "learning_rate": 0.00010810600155884645,
      "loss": 1.236,
      "step": 1230
    },
    {
      "epoch": 1.4222604704532416,
      "grad_norm": 1.2554677724838257,
      "learning_rate": 0.0001073265783320343,
      "loss": 1.023,
      "step": 1240
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 1.9774502515792847,
      "learning_rate": 0.00010654715510522214,
      "loss": 1.2516,
      "step": 1250
    },
    {
      "epoch": 1.4337349397590362,
      "eval_loss": 1.1851224899291992,
      "eval_runtime": 97.7449,
      "eval_samples_per_second": 7.929,
      "eval_steps_per_second": 1.985,
      "step": 1250
    },
    {
      "epoch": 1.4452094090648306,
      "grad_norm": 1.2457994222640991,
      "learning_rate": 0.00010576773187840999,
      "loss": 1.0531,
      "step": 1260
    },
    {
      "epoch": 1.4566838783706253,
      "grad_norm": 1.3021001815795898,
      "learning_rate": 0.00010498830865159783,
      "loss": 1.0851,
      "step": 1270
    },
    {
      "epoch": 1.46815834767642,
      "grad_norm": 1.1276650428771973,
      "learning_rate": 0.00010420888542478566,
      "loss": 1.0132,
      "step": 1280
    },
    {
      "epoch": 1.4796328169822146,
      "grad_norm": 1.6464382410049438,
      "learning_rate": 0.00010342946219797351,
      "loss": 1.0426,
      "step": 1290
    },
    {
      "epoch": 1.4911072862880093,
      "grad_norm": 1.1278955936431885,
      "learning_rate": 0.00010265003897116134,
      "loss": 0.9979,
      "step": 1300
    },
    {
      "epoch": 1.4911072862880093,
      "eval_loss": 1.1744601726531982,
      "eval_runtime": 97.701,
      "eval_samples_per_second": 7.932,
      "eval_steps_per_second": 1.986,
      "step": 1300
    },
    {
      "epoch": 1.5025817555938037,
      "grad_norm": 1.19625723361969,
      "learning_rate": 0.0001018706157443492,
      "loss": 1.0027,
      "step": 1310
    },
    {
      "epoch": 1.5140562248995983,
      "grad_norm": 1.4894537925720215,
      "learning_rate": 0.00010109119251753703,
      "loss": 1.0643,
      "step": 1320
    },
    {
      "epoch": 1.525530694205393,
      "grad_norm": 1.2181956768035889,
      "learning_rate": 0.00010031176929072488,
      "loss": 0.9877,
      "step": 1330
    },
    {
      "epoch": 1.5370051635111877,
      "grad_norm": 1.8824595212936401,
      "learning_rate": 9.953234606391271e-05,
      "loss": 1.0226,
      "step": 1340
    },
    {
      "epoch": 1.5484796328169823,
      "grad_norm": 1.213613510131836,
      "learning_rate": 9.875292283710055e-05,
      "loss": 0.9416,
      "step": 1350
    },
    {
      "epoch": 1.5484796328169823,
      "eval_loss": 1.1575331687927246,
      "eval_runtime": 97.6487,
      "eval_samples_per_second": 7.937,
      "eval_steps_per_second": 1.987,
      "step": 1350
    },
    {
      "epoch": 1.5599541021227767,
      "grad_norm": 1.427335262298584,
      "learning_rate": 9.79734996102884e-05,
      "loss": 0.9124,
      "step": 1360
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 1.0356101989746094,
      "learning_rate": 9.719407638347622e-05,
      "loss": 1.1001,
      "step": 1370
    },
    {
      "epoch": 1.582903040734366,
      "grad_norm": 1.4180644750595093,
      "learning_rate": 9.641465315666406e-05,
      "loss": 1.0334,
      "step": 1380
    },
    {
      "epoch": 1.5943775100401605,
      "grad_norm": 1.8052705526351929,
      "learning_rate": 9.563522992985191e-05,
      "loss": 1.1248,
      "step": 1390
    },
    {
      "epoch": 1.6058519793459554,
      "grad_norm": 1.1527214050292969,
      "learning_rate": 9.485580670303975e-05,
      "loss": 1.1048,
      "step": 1400
    },
    {
      "epoch": 1.6058519793459554,
      "eval_loss": 1.134573221206665,
      "eval_runtime": 97.7323,
      "eval_samples_per_second": 7.93,
      "eval_steps_per_second": 1.985,
      "step": 1400
    },
    {
      "epoch": 1.6173264486517498,
      "grad_norm": 1.4921854734420776,
      "learning_rate": 9.407638347622759e-05,
      "loss": 1.1234,
      "step": 1410
    },
    {
      "epoch": 1.6288009179575444,
      "grad_norm": 1.2872427701950073,
      "learning_rate": 9.329696024941543e-05,
      "loss": 0.9813,
      "step": 1420
    },
    {
      "epoch": 1.640275387263339,
      "grad_norm": 1.176862359046936,
      "learning_rate": 9.251753702260328e-05,
      "loss": 0.9358,
      "step": 1430
    },
    {
      "epoch": 1.6517498565691335,
      "grad_norm": 1.498274803161621,
      "learning_rate": 9.173811379579112e-05,
      "loss": 1.0109,
      "step": 1440
    },
    {
      "epoch": 1.6632243258749284,
      "grad_norm": 1.7296452522277832,
      "learning_rate": 9.095869056897896e-05,
      "loss": 1.074,
      "step": 1450
    },
    {
      "epoch": 1.6632243258749284,
      "eval_loss": 1.1154934167861938,
      "eval_runtime": 97.6999,
      "eval_samples_per_second": 7.932,
      "eval_steps_per_second": 1.986,
      "step": 1450
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 1.5295072793960571,
      "learning_rate": 9.01792673421668e-05,
      "loss": 1.0796,
      "step": 1460
    },
    {
      "epoch": 1.6861732644865175,
      "grad_norm": 1.203314185142517,
      "learning_rate": 8.939984411535464e-05,
      "loss": 1.0945,
      "step": 1470
    },
    {
      "epoch": 1.6976477337923122,
      "grad_norm": 1.6594547033309937,
      "learning_rate": 8.862042088854249e-05,
      "loss": 1.0006,
      "step": 1480
    },
    {
      "epoch": 1.7091222030981066,
      "grad_norm": 1.5139126777648926,
      "learning_rate": 8.784099766173033e-05,
      "loss": 1.0717,
      "step": 1490
    },
    {
      "epoch": 1.7205966724039015,
      "grad_norm": 1.8014330863952637,
      "learning_rate": 8.706157443491817e-05,
      "loss": 0.9418,
      "step": 1500
    },
    {
      "epoch": 1.7205966724039015,
      "eval_loss": 1.0964802503585815,
      "eval_runtime": 97.544,
      "eval_samples_per_second": 7.945,
      "eval_steps_per_second": 1.989,
      "step": 1500
    },
    {
      "epoch": 1.732071141709696,
      "grad_norm": 1.439555287361145,
      "learning_rate": 8.628215120810601e-05,
      "loss": 0.9564,
      "step": 1510
    },
    {
      "epoch": 1.7435456110154905,
      "grad_norm": 1.1408075094223022,
      "learning_rate": 8.550272798129385e-05,
      "loss": 0.9469,
      "step": 1520
    },
    {
      "epoch": 1.7550200803212852,
      "grad_norm": 1.6396363973617554,
      "learning_rate": 8.47233047544817e-05,
      "loss": 0.9504,
      "step": 1530
    },
    {
      "epoch": 1.7664945496270796,
      "grad_norm": 1.5478334426879883,
      "learning_rate": 8.394388152766954e-05,
      "loss": 0.9394,
      "step": 1540
    },
    {
      "epoch": 1.7779690189328745,
      "grad_norm": 1.2670589685440063,
      "learning_rate": 8.316445830085737e-05,
      "loss": 0.9847,
      "step": 1550
    },
    {
      "epoch": 1.7779690189328745,
      "eval_loss": 1.0765661001205444,
      "eval_runtime": 97.7055,
      "eval_samples_per_second": 7.932,
      "eval_steps_per_second": 1.986,
      "step": 1550
    },
    {
      "epoch": 1.789443488238669,
      "grad_norm": 1.7236757278442383,
      "learning_rate": 8.238503507404521e-05,
      "loss": 1.0354,
      "step": 1560
    },
    {
      "epoch": 1.8009179575444636,
      "grad_norm": 1.4549039602279663,
      "learning_rate": 8.160561184723305e-05,
      "loss": 1.0419,
      "step": 1570
    },
    {
      "epoch": 1.8123924268502583,
      "grad_norm": 2.198608636856079,
      "learning_rate": 8.082618862042089e-05,
      "loss": 0.9123,
      "step": 1580
    },
    {
      "epoch": 1.8238668961560527,
      "grad_norm": 1.2161900997161865,
      "learning_rate": 8.004676539360873e-05,
      "loss": 0.9902,
      "step": 1590
    },
    {
      "epoch": 1.8353413654618473,
      "grad_norm": 1.4668108224868774,
      "learning_rate": 7.926734216679658e-05,
      "loss": 0.9723,
      "step": 1600
    },
    {
      "epoch": 1.8353413654618473,
      "eval_loss": 1.0679999589920044,
      "eval_runtime": 97.6763,
      "eval_samples_per_second": 7.934,
      "eval_steps_per_second": 1.986,
      "step": 1600
    },
    {
      "epoch": 1.846815834767642,
      "grad_norm": 1.661269187927246,
      "learning_rate": 7.848791893998442e-05,
      "loss": 1.0846,
      "step": 1610
    },
    {
      "epoch": 1.8582903040734366,
      "grad_norm": 1.4890575408935547,
      "learning_rate": 7.770849571317226e-05,
      "loss": 0.9492,
      "step": 1620
    },
    {
      "epoch": 1.8697647733792313,
      "grad_norm": 1.4901766777038574,
      "learning_rate": 7.69290724863601e-05,
      "loss": 1.0173,
      "step": 1630
    },
    {
      "epoch": 1.8812392426850257,
      "grad_norm": 1.9200727939605713,
      "learning_rate": 7.614964925954795e-05,
      "loss": 0.9461,
      "step": 1640
    },
    {
      "epoch": 1.8927137119908204,
      "grad_norm": 2.805935859680176,
      "learning_rate": 7.537022603273577e-05,
      "loss": 0.8869,
      "step": 1650
    },
    {
      "epoch": 1.8927137119908204,
      "eval_loss": 1.0444293022155762,
      "eval_runtime": 97.6888,
      "eval_samples_per_second": 7.933,
      "eval_steps_per_second": 1.986,
      "step": 1650
    },
    {
      "epoch": 1.904188181296615,
      "grad_norm": 1.519463300704956,
      "learning_rate": 7.459080280592362e-05,
      "loss": 0.8828,
      "step": 1660
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 2.47082257270813,
      "learning_rate": 7.381137957911146e-05,
      "loss": 0.9367,
      "step": 1670
    },
    {
      "epoch": 1.9271371199082044,
      "grad_norm": 1.657278060913086,
      "learning_rate": 7.30319563522993e-05,
      "loss": 1.0014,
      "step": 1680
    },
    {
      "epoch": 1.9386115892139988,
      "grad_norm": 1.8397722244262695,
      "learning_rate": 7.225253312548714e-05,
      "loss": 0.9619,
      "step": 1690
    },
    {
      "epoch": 1.9500860585197934,
      "grad_norm": 1.2717082500457764,
      "learning_rate": 7.147310989867498e-05,
      "loss": 0.8625,
      "step": 1700
    },
    {
      "epoch": 1.9500860585197934,
      "eval_loss": 1.0125211477279663,
      "eval_runtime": 97.6629,
      "eval_samples_per_second": 7.935,
      "eval_steps_per_second": 1.986,
      "step": 1700
    },
    {
      "epoch": 1.961560527825588,
      "grad_norm": 1.6195050477981567,
      "learning_rate": 7.069368667186283e-05,
      "loss": 0.9089,
      "step": 1710
    },
    {
      "epoch": 1.9730349971313825,
      "grad_norm": 1.5869947671890259,
      "learning_rate": 6.991426344505067e-05,
      "loss": 0.7835,
      "step": 1720
    },
    {
      "epoch": 1.9845094664371774,
      "grad_norm": 1.138334035873413,
      "learning_rate": 6.913484021823851e-05,
      "loss": 0.9517,
      "step": 1730
    },
    {
      "epoch": 1.9959839357429718,
      "grad_norm": 1.546404242515564,
      "learning_rate": 6.835541699142635e-05,
      "loss": 0.8854,
      "step": 1740
    },
    {
      "epoch": 2.0068846815834767,
      "grad_norm": 1.4552903175354004,
      "learning_rate": 6.757599376461418e-05,
      "loss": 0.8932,
      "step": 1750
    },
    {
      "epoch": 2.0068846815834767,
      "eval_loss": 1.009821891784668,
      "eval_runtime": 97.7404,
      "eval_samples_per_second": 7.929,
      "eval_steps_per_second": 1.985,
      "step": 1750
    },
    {
      "epoch": 2.0183591508892715,
      "grad_norm": 2.4923553466796875,
      "learning_rate": 6.679657053780202e-05,
      "loss": 0.7912,
      "step": 1760
    },
    {
      "epoch": 2.029833620195066,
      "grad_norm": 1.3963357210159302,
      "learning_rate": 6.601714731098986e-05,
      "loss": 0.7575,
      "step": 1770
    },
    {
      "epoch": 2.0413080895008604,
      "grad_norm": 1.8203363418579102,
      "learning_rate": 6.523772408417771e-05,
      "loss": 0.7866,
      "step": 1780
    },
    {
      "epoch": 2.0527825588066553,
      "grad_norm": 1.810288667678833,
      "learning_rate": 6.445830085736555e-05,
      "loss": 0.739,
      "step": 1790
    },
    {
      "epoch": 2.0642570281124497,
      "grad_norm": 1.3675979375839233,
      "learning_rate": 6.367887763055339e-05,
      "loss": 0.7459,
      "step": 1800
    },
    {
      "epoch": 2.0642570281124497,
      "eval_loss": 0.9986279010772705,
      "eval_runtime": 97.7583,
      "eval_samples_per_second": 7.928,
      "eval_steps_per_second": 1.984,
      "step": 1800
    },
    {
      "epoch": 2.0757314974182446,
      "grad_norm": 1.6576865911483765,
      "learning_rate": 6.289945440374123e-05,
      "loss": 0.7274,
      "step": 1810
    },
    {
      "epoch": 2.087205966724039,
      "grad_norm": 2.220271348953247,
      "learning_rate": 6.212003117692908e-05,
      "loss": 0.708,
      "step": 1820
    },
    {
      "epoch": 2.0986804360298335,
      "grad_norm": 1.5056006908416748,
      "learning_rate": 6.134060795011692e-05,
      "loss": 0.7741,
      "step": 1830
    },
    {
      "epoch": 2.1101549053356283,
      "grad_norm": 1.51918625831604,
      "learning_rate": 6.056118472330475e-05,
      "loss": 0.6357,
      "step": 1840
    },
    {
      "epoch": 2.1216293746414228,
      "grad_norm": 2.4097633361816406,
      "learning_rate": 5.9781761496492595e-05,
      "loss": 0.7145,
      "step": 1850
    },
    {
      "epoch": 2.1216293746414228,
      "eval_loss": 0.9957878589630127,
      "eval_runtime": 97.8382,
      "eval_samples_per_second": 7.921,
      "eval_steps_per_second": 1.983,
      "step": 1850
    },
    {
      "epoch": 2.1331038439472176,
      "grad_norm": 1.3383220434188843,
      "learning_rate": 5.900233826968044e-05,
      "loss": 0.7115,
      "step": 1860
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 2.258233070373535,
      "learning_rate": 5.822291504286828e-05,
      "loss": 0.7137,
      "step": 1870
    },
    {
      "epoch": 2.1560527825588065,
      "grad_norm": 1.746773362159729,
      "learning_rate": 5.7443491816056114e-05,
      "loss": 0.7401,
      "step": 1880
    },
    {
      "epoch": 2.1675272518646014,
      "grad_norm": 1.479756474494934,
      "learning_rate": 5.6664068589243956e-05,
      "loss": 0.7979,
      "step": 1890
    },
    {
      "epoch": 2.179001721170396,
      "grad_norm": 1.482707142829895,
      "learning_rate": 5.58846453624318e-05,
      "loss": 0.6979,
      "step": 1900
    },
    {
      "epoch": 2.179001721170396,
      "eval_loss": 0.9801312685012817,
      "eval_runtime": 97.8136,
      "eval_samples_per_second": 7.923,
      "eval_steps_per_second": 1.983,
      "step": 1900
    },
    {
      "epoch": 2.1904761904761907,
      "grad_norm": 2.5191824436187744,
      "learning_rate": 5.510522213561965e-05,
      "loss": 0.7246,
      "step": 1910
    },
    {
      "epoch": 2.201950659781985,
      "grad_norm": 2.2498645782470703,
      "learning_rate": 5.432579890880749e-05,
      "loss": 0.6502,
      "step": 1920
    },
    {
      "epoch": 2.2134251290877796,
      "grad_norm": 1.5376359224319458,
      "learning_rate": 5.354637568199533e-05,
      "loss": 0.6625,
      "step": 1930
    },
    {
      "epoch": 2.2248995983935744,
      "grad_norm": 1.56600821018219,
      "learning_rate": 5.276695245518317e-05,
      "loss": 0.6979,
      "step": 1940
    },
    {
      "epoch": 2.236374067699369,
      "grad_norm": 2.084550142288208,
      "learning_rate": 5.1987529228371015e-05,
      "loss": 0.7206,
      "step": 1950
    },
    {
      "epoch": 2.236374067699369,
      "eval_loss": 0.9738890528678894,
      "eval_runtime": 97.8138,
      "eval_samples_per_second": 7.923,
      "eval_steps_per_second": 1.983,
      "step": 1950
    },
    {
      "epoch": 2.2478485370051633,
      "grad_norm": 1.8456604480743408,
      "learning_rate": 5.120810600155885e-05,
      "loss": 0.7018,
      "step": 1960
    },
    {
      "epoch": 2.259323006310958,
      "grad_norm": 2.492285966873169,
      "learning_rate": 5.042868277474669e-05,
      "loss": 0.6865,
      "step": 1970
    },
    {
      "epoch": 2.2707974756167526,
      "grad_norm": 1.4673794507980347,
      "learning_rate": 4.964925954793453e-05,
      "loss": 0.6827,
      "step": 1980
    },
    {
      "epoch": 2.2822719449225475,
      "grad_norm": 1.9307079315185547,
      "learning_rate": 4.886983632112237e-05,
      "loss": 0.7558,
      "step": 1990
    },
    {
      "epoch": 2.293746414228342,
      "grad_norm": 1.6468321084976196,
      "learning_rate": 4.809041309431021e-05,
      "loss": 0.6771,
      "step": 2000
    },
    {
      "epoch": 2.293746414228342,
      "eval_loss": 0.9616793990135193,
      "eval_runtime": 97.752,
      "eval_samples_per_second": 7.928,
      "eval_steps_per_second": 1.985,
      "step": 2000
    },
    {
      "epoch": 2.305220883534137,
      "grad_norm": 1.9988598823547363,
      "learning_rate": 4.7310989867498054e-05,
      "loss": 0.73,
      "step": 2010
    },
    {
      "epoch": 2.316695352839931,
      "grad_norm": 2.1638123989105225,
      "learning_rate": 4.6531566640685896e-05,
      "loss": 0.6824,
      "step": 2020
    },
    {
      "epoch": 2.3281698221457257,
      "grad_norm": 1.506039023399353,
      "learning_rate": 4.575214341387374e-05,
      "loss": 0.7252,
      "step": 2030
    },
    {
      "epoch": 2.3396442914515205,
      "grad_norm": 2.817888021469116,
      "learning_rate": 4.497272018706158e-05,
      "loss": 0.6749,
      "step": 2040
    },
    {
      "epoch": 2.351118760757315,
      "grad_norm": 1.8227123022079468,
      "learning_rate": 4.419329696024942e-05,
      "loss": 0.6485,
      "step": 2050
    },
    {
      "epoch": 2.351118760757315,
      "eval_loss": 0.9523448348045349,
      "eval_runtime": 97.8097,
      "eval_samples_per_second": 7.924,
      "eval_steps_per_second": 1.983,
      "step": 2050
    },
    {
      "epoch": 2.3625932300631094,
      "grad_norm": 2.3937056064605713,
      "learning_rate": 4.341387373343726e-05,
      "loss": 0.5824,
      "step": 2060
    },
    {
      "epoch": 2.3740676993689043,
      "grad_norm": 1.6746245622634888,
      "learning_rate": 4.26344505066251e-05,
      "loss": 0.6056,
      "step": 2070
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 1.540030598640442,
      "learning_rate": 4.185502727981294e-05,
      "loss": 0.6382,
      "step": 2080
    },
    {
      "epoch": 2.3970166379804936,
      "grad_norm": 2.276254653930664,
      "learning_rate": 4.1075604053000784e-05,
      "loss": 0.6756,
      "step": 2090
    },
    {
      "epoch": 2.408491107286288,
      "grad_norm": 1.4520463943481445,
      "learning_rate": 4.0296180826188626e-05,
      "loss": 0.6959,
      "step": 2100
    },
    {
      "epoch": 2.408491107286288,
      "eval_loss": 0.9402139186859131,
      "eval_runtime": 97.7501,
      "eval_samples_per_second": 7.928,
      "eval_steps_per_second": 1.985,
      "step": 2100
    },
    {
      "epoch": 2.4199655765920824,
      "grad_norm": 0.8591198921203613,
      "learning_rate": 3.951675759937646e-05,
      "loss": 0.7467,
      "step": 2110
    },
    {
      "epoch": 2.4314400458978773,
      "grad_norm": 2.0744943618774414,
      "learning_rate": 3.87373343725643e-05,
      "loss": 0.8201,
      "step": 2120
    },
    {
      "epoch": 2.4429145152036718,
      "grad_norm": 1.3758034706115723,
      "learning_rate": 3.7957911145752145e-05,
      "loss": 0.7419,
      "step": 2130
    },
    {
      "epoch": 2.4543889845094666,
      "grad_norm": 2.1884169578552246,
      "learning_rate": 3.717848791893999e-05,
      "loss": 0.6659,
      "step": 2140
    },
    {
      "epoch": 2.465863453815261,
      "grad_norm": 1.6597990989685059,
      "learning_rate": 3.639906469212783e-05,
      "loss": 0.8148,
      "step": 2150
    },
    {
      "epoch": 2.465863453815261,
      "eval_loss": 0.9275453686714172,
      "eval_runtime": 97.7186,
      "eval_samples_per_second": 7.931,
      "eval_steps_per_second": 1.985,
      "step": 2150
    },
    {
      "epoch": 2.4773379231210555,
      "grad_norm": 1.9488710165023804,
      "learning_rate": 3.5619641465315665e-05,
      "loss": 0.7404,
      "step": 2160
    },
    {
      "epoch": 2.4888123924268504,
      "grad_norm": 1.8010413646697998,
      "learning_rate": 3.484021823850351e-05,
      "loss": 0.7937,
      "step": 2170
    },
    {
      "epoch": 2.500286861732645,
      "grad_norm": 1.7375096082687378,
      "learning_rate": 3.406079501169135e-05,
      "loss": 0.7119,
      "step": 2180
    },
    {
      "epoch": 2.5117613310384392,
      "grad_norm": 2.2323899269104004,
      "learning_rate": 3.328137178487919e-05,
      "loss": 0.6239,
      "step": 2190
    },
    {
      "epoch": 2.523235800344234,
      "grad_norm": 2.1671202182769775,
      "learning_rate": 3.250194855806703e-05,
      "loss": 0.6781,
      "step": 2200
    },
    {
      "epoch": 2.523235800344234,
      "eval_loss": 0.9236553311347961,
      "eval_runtime": 97.7322,
      "eval_samples_per_second": 7.93,
      "eval_steps_per_second": 1.985,
      "step": 2200
    },
    {
      "epoch": 2.5347102696500285,
      "grad_norm": 1.4794435501098633,
      "learning_rate": 3.172252533125487e-05,
      "loss": 0.7065,
      "step": 2210
    },
    {
      "epoch": 2.5461847389558234,
      "grad_norm": 2.0188541412353516,
      "learning_rate": 3.094310210444271e-05,
      "loss": 0.6809,
      "step": 2220
    },
    {
      "epoch": 2.557659208261618,
      "grad_norm": 2.350343704223633,
      "learning_rate": 3.0163678877630553e-05,
      "loss": 0.6922,
      "step": 2230
    },
    {
      "epoch": 2.5691336775674127,
      "grad_norm": 2.248966693878174,
      "learning_rate": 2.9384255650818395e-05,
      "loss": 0.7869,
      "step": 2240
    },
    {
      "epoch": 2.580608146873207,
      "grad_norm": 1.7056050300598145,
      "learning_rate": 2.860483242400624e-05,
      "loss": 0.6736,
      "step": 2250
    },
    {
      "epoch": 2.580608146873207,
      "eval_loss": 0.8978383541107178,
      "eval_runtime": 97.7056,
      "eval_samples_per_second": 7.932,
      "eval_steps_per_second": 1.986,
      "step": 2250
    },
    {
      "epoch": 2.5920826161790016,
      "grad_norm": 1.486523985862732,
      "learning_rate": 2.782540919719408e-05,
      "loss": 0.6231,
      "step": 2260
    },
    {
      "epoch": 2.6035570854847965,
      "grad_norm": 1.3510125875473022,
      "learning_rate": 2.704598597038192e-05,
      "loss": 0.6566,
      "step": 2270
    },
    {
      "epoch": 2.615031554790591,
      "grad_norm": 1.5601708889007568,
      "learning_rate": 2.6266562743569763e-05,
      "loss": 0.6957,
      "step": 2280
    },
    {
      "epoch": 2.6265060240963853,
      "grad_norm": 1.6968531608581543,
      "learning_rate": 2.54871395167576e-05,
      "loss": 0.6725,
      "step": 2290
    },
    {
      "epoch": 2.63798049340218,
      "grad_norm": 1.6931241750717163,
      "learning_rate": 2.4707716289945444e-05,
      "loss": 0.7117,
      "step": 2300
    },
    {
      "epoch": 2.63798049340218,
      "eval_loss": 0.8936493396759033,
      "eval_runtime": 97.7198,
      "eval_samples_per_second": 7.931,
      "eval_steps_per_second": 1.985,
      "step": 2300
    },
    {
      "epoch": 2.6494549627079746,
      "grad_norm": 2.409907579421997,
      "learning_rate": 2.3928293063133282e-05,
      "loss": 0.6593,
      "step": 2310
    },
    {
      "epoch": 2.6609294320137695,
      "grad_norm": 1.5110697746276855,
      "learning_rate": 2.3148869836321124e-05,
      "loss": 0.8094,
      "step": 2320
    },
    {
      "epoch": 2.672403901319564,
      "grad_norm": 2.5393869876861572,
      "learning_rate": 2.2369446609508966e-05,
      "loss": 0.6552,
      "step": 2330
    },
    {
      "epoch": 2.683878370625359,
      "grad_norm": 2.380321741104126,
      "learning_rate": 2.1590023382696805e-05,
      "loss": 0.6942,
      "step": 2340
    },
    {
      "epoch": 2.6953528399311533,
      "grad_norm": 1.4298049211502075,
      "learning_rate": 2.0810600155884647e-05,
      "loss": 0.6939,
      "step": 2350
    },
    {
      "epoch": 2.6953528399311533,
      "eval_loss": 0.8784186244010925,
      "eval_runtime": 97.7746,
      "eval_samples_per_second": 7.926,
      "eval_steps_per_second": 1.984,
      "step": 2350
    },
    {
      "epoch": 2.7068273092369477,
      "grad_norm": 1.6087948083877563,
      "learning_rate": 2.0031176929072486e-05,
      "loss": 0.5509,
      "step": 2360
    },
    {
      "epoch": 2.7183017785427426,
      "grad_norm": 1.5545926094055176,
      "learning_rate": 1.9251753702260328e-05,
      "loss": 0.6603,
      "step": 2370
    },
    {
      "epoch": 2.729776247848537,
      "grad_norm": 1.1629904508590698,
      "learning_rate": 1.847233047544817e-05,
      "loss": 0.6112,
      "step": 2380
    },
    {
      "epoch": 2.7412507171543314,
      "grad_norm": 2.405019760131836,
      "learning_rate": 1.769290724863601e-05,
      "loss": 0.5925,
      "step": 2390
    },
    {
      "epoch": 2.7527251864601263,
      "grad_norm": 2.0815467834472656,
      "learning_rate": 1.691348402182385e-05,
      "loss": 0.6958,
      "step": 2400
    },
    {
      "epoch": 2.7527251864601263,
      "eval_loss": 0.8734346628189087,
      "eval_runtime": 97.7364,
      "eval_samples_per_second": 7.929,
      "eval_steps_per_second": 1.985,
      "step": 2400
    },
    {
      "epoch": 2.7641996557659207,
      "grad_norm": 1.5586286783218384,
      "learning_rate": 1.6134060795011693e-05,
      "loss": 0.649,
      "step": 2410
    },
    {
      "epoch": 2.775674125071715,
      "grad_norm": 1.9190406799316406,
      "learning_rate": 1.5354637568199535e-05,
      "loss": 0.6918,
      "step": 2420
    },
    {
      "epoch": 2.78714859437751,
      "grad_norm": 2.5236260890960693,
      "learning_rate": 1.4575214341387375e-05,
      "loss": 0.5407,
      "step": 2430
    },
    {
      "epoch": 2.7986230636833045,
      "grad_norm": 1.7566211223602295,
      "learning_rate": 1.3795791114575216e-05,
      "loss": 0.618,
      "step": 2440
    },
    {
      "epoch": 2.8100975329890994,
      "grad_norm": 1.6059030294418335,
      "learning_rate": 1.3016367887763056e-05,
      "loss": 0.5999,
      "step": 2450
    },
    {
      "epoch": 2.8100975329890994,
      "eval_loss": 0.8737545013427734,
      "eval_runtime": 97.7948,
      "eval_samples_per_second": 7.925,
      "eval_steps_per_second": 1.984,
      "step": 2450
    },
    {
      "epoch": 2.821572002294894,
      "grad_norm": 1.3722058534622192,
      "learning_rate": 1.2236944660950896e-05,
      "loss": 0.7181,
      "step": 2460
    },
    {
      "epoch": 2.8330464716006887,
      "grad_norm": 1.71351957321167,
      "learning_rate": 1.1457521434138739e-05,
      "loss": 0.5887,
      "step": 2470
    },
    {
      "epoch": 2.844520940906483,
      "grad_norm": 1.526252269744873,
      "learning_rate": 1.0678098207326579e-05,
      "loss": 0.6736,
      "step": 2480
    },
    {
      "epoch": 2.8559954102122775,
      "grad_norm": 1.8097580671310425,
      "learning_rate": 9.898674980514421e-06,
      "loss": 0.5866,
      "step": 2490
    },
    {
      "epoch": 2.8674698795180724,
      "grad_norm": 1.378719449043274,
      "learning_rate": 9.119251753702261e-06,
      "loss": 0.5379,
      "step": 2500
    },
    {
      "epoch": 2.8674698795180724,
      "eval_loss": 0.871105432510376,
      "eval_runtime": 97.7669,
      "eval_samples_per_second": 7.927,
      "eval_steps_per_second": 1.984,
      "step": 2500
    },
    {
      "epoch": 2.878944348823867,
      "grad_norm": 1.7423076629638672,
      "learning_rate": 8.339828526890102e-06,
      "loss": 0.5592,
      "step": 2510
    },
    {
      "epoch": 2.8904188181296613,
      "grad_norm": 2.309931755065918,
      "learning_rate": 7.560405300077943e-06,
      "loss": 0.7223,
      "step": 2520
    },
    {
      "epoch": 2.901893287435456,
      "grad_norm": 1.5860755443572998,
      "learning_rate": 6.780982073265783e-06,
      "loss": 0.6275,
      "step": 2530
    },
    {
      "epoch": 2.9133677567412506,
      "grad_norm": 1.7223798036575317,
      "learning_rate": 6.0015588464536245e-06,
      "loss": 0.6117,
      "step": 2540
    },
    {
      "epoch": 2.9248422260470455,
      "grad_norm": 1.0163147449493408,
      "learning_rate": 5.222135619641466e-06,
      "loss": 0.5932,
      "step": 2550
    },
    {
      "epoch": 2.9248422260470455,
      "eval_loss": 0.8675029277801514,
      "eval_runtime": 97.8132,
      "eval_samples_per_second": 7.923,
      "eval_steps_per_second": 1.983,
      "step": 2550
    },
    {
      "epoch": 2.93631669535284,
      "grad_norm": 1.5550060272216797,
      "learning_rate": 4.442712392829307e-06,
      "loss": 0.5996,
      "step": 2560
    },
    {
      "epoch": 2.9477911646586348,
      "grad_norm": 1.7835993766784668,
      "learning_rate": 3.6632891660171474e-06,
      "loss": 0.6255,
      "step": 2570
    },
    {
      "epoch": 2.959265633964429,
      "grad_norm": 1.8301857709884644,
      "learning_rate": 2.8838659392049886e-06,
      "loss": 0.5969,
      "step": 2580
    },
    {
      "epoch": 2.9707401032702236,
      "grad_norm": 1.5579184293746948,
      "learning_rate": 2.1044427123928294e-06,
      "loss": 0.659,
      "step": 2590
    },
    {
      "epoch": 2.9822145725760185,
      "grad_norm": 1.5853115320205688,
      "learning_rate": 1.3250194855806704e-06,
      "loss": 0.6387,
      "step": 2600
    },
    {
      "epoch": 2.9822145725760185,
      "eval_loss": 0.865452766418457,
      "eval_runtime": 97.74,
      "eval_samples_per_second": 7.929,
      "eval_steps_per_second": 1.985,
      "step": 2600
    },
    {
      "epoch": 2.993689041881813,
      "grad_norm": 1.0924170017242432,
      "learning_rate": 5.455962587685114e-07,
      "loss": 0.7104,
      "step": 2610
    }
  ],
  "logging_steps": 10,
  "max_steps": 2616,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.046118697229353e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
